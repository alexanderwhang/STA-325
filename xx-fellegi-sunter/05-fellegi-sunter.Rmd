
---
title: "Module 5: Fellegi-Sunter Method"
author: "Rebecca C. Steorts"
institute: joint with Olivier Binette
output: 
     beamer_presentation:
      includes: 
          in_header: custom2.tex
font-size: 8px
---

## Reading

- Binette and Steorts (2020)
- Newcombe et al. (1959)
- Fellegi and Sunter (1969)

## Agenda

- Soundex algorithm 
- Newcombe algorithm 
- Fellegi and Sunter method

## Load R Packages

```{r, echo=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      fig.width=4, fig.height=3, 
                      fig.align="center")
library(RecordLinkage)
library(blink)
library(phonics)
```

## Background

- Soundex algorithm
- Likelihood ratio tests (LRT)

## Soundex

**Soundex** is a phonetic algorithm for indexing names by sound, as pronounced in English. 

- The goal is for similar words to be encoded to the same representation so that they can be matched despite minor differences in spelling.
- The Soundex algorithm was one of the first types of blocking used to our knowledge since it's intuitive and easy to use. 

## Example of Soundex algorithm

```{r}
soundex("Rebecca")
soundex("Rebekah")
```

## Example of Soundex algorithm

```{r}
soundex("Beka")
soundex("Becca")
soundex("Becky")

```

## Likelihood ratio test (LRT)

Please review or learn about LRTs if you are not familiar with these as these are the backbone of the Fellegi and Sunter method (1969). 

\url{https://www.sciencedirect.com/topics/computer-science/likelihood-ratio}

## Newcombe's Automatic Linkage of Vital Records

Newcombe et al. (1959). Published in \textit{Science}:

\begin{center}
    \includegraphics[width=\linewidth]{finalFigures/newcombe}
\end{center}

## Newcombe's Automatic Linkage of Vital Records

Newcombe et al. (1959) introduced a **probabilistic record linkage** technique and implemented it on the Datatron 205 computer.

\pause
\vspace*{2em}

The authors did the following:

\begin{itemize}
    \item Stated record linkage as a statistical problem, proposing the first unsupervised probabilistic record linkage method.
    \item Illustrated that it could be implemented on a computer.
\end{itemize}

## Newcombe's Automatic Linkage of Vital Records
    
\textbf{Goal:} Link \textbf{34,138 birth records} from 1955 in British Columbia \textbf{to 114,471 marriage records} in the preceding ten year period.



\begin{table}[h]
    \centering
    \begin{tabular}{rcc}
    \toprule
    & Marriage record & Birth record\\
    \midrule
        Husband's family name & Ayad & Ayot \\
        Wife's family name & Barr & Barr\\
        Husband's initials & J Z & J Z\\
        Wife's initials & M T & B T\\
        Husband's birth province & AB & AB\\
        Wife's birth province & PE & PE\\
        \bottomrule
    \end{tabular}
    \caption{Example of identity information from comparing marriage and birth records. This is adapted and translated from Table I of Newcombe (1969). AB and PE represent the Canadian provinces of Alberta and Prince Edward Island.}
    \label{tab:my_label}
\end{table}

## Newcombe's Automatic Linkage of Vital Records

\textbf{Main contributions}:


\begin{enumerate}
 \item Sort records by the Soundex algorithm of family names.
 \item When the Soundex coding agrees, an informal likelihood ratio test (LRT) determines if the record are matches/non-matches.
\end{enumerate}




<!-- ## Newcombe's Automatic Linkage of Vital Records -->

<!-- \textbf{Likelihood ratio test:} -->

<!-- \begin{itemize} -->
<!--     \item Suppose two records agree on the husband's first initial J. -->
<!--     \pause -->
<!--     \item Let $p_L$ be the probability of this event given that the records are an actual a match. Let $p_F$ be the probability of this event given that the records are not an actual match. -->
<!--     \pause -->
<!--     \item Let $p_R$ be the proportion of the initial ``J'' among husbands. -->
<!-- \end{itemize} -->
<!-- \pause -->
<!-- Then -->
<!-- $$p_L \approx p_R, \pause\quad p_F \approx p_R^2$$ -->
<!-- \pause -->
<!-- so -->
<!-- $$ -->
<!--     \log(p_L/p_F) \approx -\log (p_R). -->
<!-- $$ -->

<!-- \pause This is the ``matching weight.'' -->

<!-- ## Newcombe's Automatic Linkage of Vital Records -->

<!-- \textbf{Likelihood ratio test (cont'd):} -->

<!-- \begin{itemize} -->
<!--     \item If the initial is very common, e.g. $p_R = 0.1$, then -->
<!--     $$ -->
<!--         \log(p_L/p_F) \approx -\log(0.1) \approx 2.3 -->
<!--     $$ -->
<!--     places very little weight that the two records are a match. -->
<!--     \pause  -->
<!--     \item If the initial is not at all common, e.g. $p_R = 0.0001$, then -->
<!--     $$ -->
<!--         \log(p_L/p_F) \approx -\log(0.0001) \approx 9.2 -->
<!--     $$ -->
<!--     places much higher weight that the two records are a match. -->
<!-- \end{itemize} -->

## Newcombe's Automatic Linkage of Vital Records

The **performance of the method** was as follows:
\begin{itemize}
    \item 10 record pairs were processed per minutes
    \item About $98.3\%$ of the true matches were detected, and about $0.7\%$ of the linked records were not actual matches.
    \item ``by far the largest part of the effort'' was the preparation of punched card files reproducing marriage records in an adequate format.
\end{itemize}


\pause

Unfortunately, we do not know exactly how the probabilities for the likelihood ratio test were computed in all cases. 



## Probabilistic Record Linkage

The work of Newcombe et al. (1959) led to one of the most seminal papers in the literature --- Fellegi and Sunter (1969).

## The Fellegi-Sunter model

Fellegi and Sunter (1969). Published in JASA:
\begin{center}
    \includegraphics[width=\linewidth]{finalFigures/FS}
\end{center}


## The Fellegi-Sunter model

Fellegi and Sunter (1969) formalizes Newcombe et al. (1959) in a decision-theoretic framework.

\pause

Given a pair of records, Fellegi and Sunter (1969) considers three possible actions:
\begin{itemize}
    \item to \textit{link} the record pairs;
    \item to \textit{possibly link} the record pairs; or
    \item to \textit{not link} the record pairs.
\end{itemize}

An "optimal" decision rule is proposed for this.

\pause

We will focus on the **model** (rather than the decision-theoretic framework).

## The Fellegi-Sunter model

**Basic elements:**

- Two *databases* $A$ and $B$
  - Duplication *across* but not within databases (bipartite record linkage).
- *Records* with corresponding *attributes* or *fields*
  - Name, age, address, SSN, etc.

## The Fellegi-Sunter model

**Our goal:**

- Figure out which records refer to the same **entity** (a *person*, *object* or *event*.)

\pause

**How we'll do that:**

- We will consider **record pairs** from databases $A$ and $B$ to obtain multidimensional measures of similarity.
- Based on these **measures of similarity**, we will group records together that refer to the same entity. 

## The Fellegi-Sunter model

\begin{center}
\small
\begin{tabular}{cccc}
\toprule
& Field 1 & Field 2 & Field 3\\
Record no. & First name & Last name & Age\\
\midrule
1 & Olivier & Binette & 25\\
2 & Peter & Hoff & NA\\
$\vdots$ & $\vdots$ & $\vdots$& $\vdots$\\
$N_1$ & Beka & Steorts & NA\\
\bottomrule
\end{tabular}

\quad

\begin{tabular}{cccc}
\toprule
& Field 1 & Field 2 & Field 3\\
Record no. & First name & Last name & Age\\
\midrule
1 & Oliver & Binette & 26\\
2 & Brian & K & NA\\
$\vdots$ & $\vdots$ & $\vdots$& $\vdots$\\
$N_2$ & Frances & Hung & NA\\
\bottomrule
\end{tabular}
\end{center}

\textbf{Is Olivier Binette the same person as Oliver Binette?}

## The Fellegi-Sunter model

Fellegi and Sunter (1969) formalizes Newcombe et al. (1959) in a decision-theoretic framework.

\vspace*{2em}

We consider **three possible actions** for a given pair of records:
\begin{itemize}
    \item to \textit{link} them;
    \item to call them a \textit{possible link}; or
    \item to \textit{not link} them.
\end{itemize}

## A Theory for Record Linkage 

Consider **two error probabilities** (error rates):

$$
    \mu = \mathbb{P}\left(\text{linking} \mid \text{records do not match}\right),
$$

\vspace*{2em}

$$
    \lambda = \mathbb{P}\left(\text{not linking} \mid \text{records do match}\right).
$$


## A Theory for Record Linkage 


\begin{center}
      \includegraphics[width=\linewidth]{finalFigures/Scan}
\end{center}


Goal of an **optimal decision procedure**:
\vspace{0.03in}

Minimize the number of \textit{possible links}, while achieving the above error rates at fixed levels $\mu$ and $\lambda$.

## A Fundamental Theorem for Record Linkage 

Fellegi and Sunter (1969) showed that the **optimal decision procedure** is obtained by a **likelihood ratio test**. 

## Comparison Vectors

Let $$i = 1,2,\dots, N_1\times N_2$$ enumerate the set of all record pairs in $A \times B$.
\pause

- For the $i$th pair of records, we compute a corresponding **comparison vector**
$$
  \gamma_i = (\gamma_i^{(1)}, \gamma_i^{(2)}, \dots, \gamma_i^{(k)}).
$$
\pause

- Each $\gamma_i^{j}$ compares the $j$th field of the records.



Example: Let the $j$th field be "age." Then $\gamma_i^{j} = 0$ if all ages are the same and $\gamma_i^{j} = 1$ if ages different.

## Comparison Vectors

**Binary comparisons:**

- $\gamma_i^{j} \in \{0,1\}$
\pause

**Levels of agreement/disagreement:**

- $\gamma_i^{j} \in \{0, 1, 2,\dots, L_j\}$
\pause

**How they're obtained:**

- You choose!
- Use string distance functions to compare names.

## Comparison Vectors

How can we visualize the comparison vectors? 

\begin{align}
\gamma_1 &= (\gamma_1^{(1)}, \gamma_1^{(2)}, \dots, \gamma_1^{(k)}) \\
\gamma_2 &= (\gamma_2^{(1)}, \gamma_2^{(2)}, \dots, \gamma_2^{(k)}) \\
&\vdots\\
\gamma_{(N_1 \times N_2)} &= (\gamma_{(N_1 \times N_2)}^{(1)}, \gamma_{(N_1 \times N_2)}^{(2)}, \dots, \gamma_{(N_1 \times N_2)}^{(k)}) 
\end{align}

Let $$\gamma = (\gamma_1^{(1)}, \gamma_2^{(2)}, \ldots, \gamma_{(N_1 \times N_2)}^{(k)})$$


## Likelihood Ratio Test

Define

\begin{align}
m(\gamma) &= \mathbb{P}(\gamma \mid \text{the records are a match}) \\
u(\gamma) &= \mathbb{P}(\gamma \mid \text{the records are not a match})
\end{align}

\pause

Then the **matching weight** or **log-likelihood ratio** is
\begin{align}
W(\gamma) &= \log(m(\gamma) / u(\gamma))
\end{align}

## Likelihood Ratio Test

Two thresholds $T_\mu$ and $T_\lambda$ must be computed as a function of the desired error levels $\mu$ and $\lambda$.

\vspace*{2em}

Specifically, we
\begin{itemize}
  \item \textit{link} if $W(\gamma) > T_\mu$;
  \item \textit{possible link} if $T_\mu \geq W(\gamma) > T_\lambda$; and
  \item do \textit{not link} if otherwise $T_\lambda \geq W(\gamma)$.
\end{itemize}

\vspace*{2em}


We are ignoring the boundary cases (see Appendix 1 of Fellegi-Sunter (1969) for details).

## Key Questions

\begin{enumerate}
        \item How do we compute the probabilities
            $$m(\gamma) = \mathbb{P}(\gamma \mid \text{the records are a match}),$$
        $$u(\gamma) = \mathbb{P}(\gamma \mid \text{the records are not a match})?$$
        \item Do we care about the error rates
        $$
    \mu = \mathbb{P}\left(\text{linking} | \text{records don't match}\right),
    $$
    $$
        \lambda = \mathbb{P}\left(\text{not linking} | \text{records are a match}\right)?
    $$
    \end{enumerate}


## Proposed methods

Fellegi and Sunter (1969) proposed two methods in their paper for calculating $m(\gamma)$ and $u(\gamma).$

They referred to these as Method 1 and Method 2, and thus, we will stick with the same terminology. 


## Method 1

**Method 1**: This is roughly what Newcombe el al (1959) proposed: 

- Completely unsupervised
- Uses frequency of occurence of names, ages, addresses as additional information
- Requires prior knowledge of error rates ($\mu$ and $\lambda$). For some problems, these are known or can be estimated. 

Example: At the U.S. Census Bureau, they currently use Method 1 in production for the decennial census and have prior knowledge of the error rates from working on the problem for a very long period of time. 

## Method 2

The second method applies to the comparison vectors $\gamma = (\gamma_1^{(1)}, \gamma_2^{(2)}, \ldots, \gamma_{(N_1 \times N_2)}^{(k)})$ under the following assumptions: 

\begin{itemize}
        \item $\gamma_i^j \in \{0,1\}$ is a binary comparison vector
        \item $\{\gamma_i^j\}_{j=1}^k$ is conditionally independent given the true match or non-match status of the pair of records.
\end{itemize}

## Method 2

Let $M$ be the set of true matches among record pairs, $U$ be the set of true non-matches.

Abusing notation, the idea is to consider the equations:
    \begin{align*}
    P(\gamma) &= P(\gamma\mid M)P(M) + P(\gamma\mid U)P(U)\\
       &= \left\{\prod_{i=1}^k P(\gamma_i | M)\right\} P(M) + \left\{\prod_{i=1}^k P(\gamma_i | U)\right\} P(U)\\
        &= \left\{\prod_{i=1}^k m(\gamma_i)\right\} P(M) + \left\{\prod_{i=1}^k u(\gamma_i)\right\} (1-P(M)),
    \end{align*}
    which are $2^k - 1$ equations for $2k + 1$ variables; there can be a solution when $k \geq 3$.
    
To solve for $m(\gamma_i)$ and $u(\gamma_i),$ the EM algorithm is used.\footnote{The EM algorithm iteratively solves for the unknown $m$ and $u$ parameters, where it finds a local maximum for the likelihood.}  
    
    
## Final Question

Do we care about the error rates
$$
    \mu = \mathbb{P}\left(\text{linking} | \text{records don't match}\right),
$$
$$
        \lambda = \mathbb{P}\left(\text{not linking} | \text{records are a match}\right)?
$$
   
In practice, we do not know if a given pair of record is a match or not, so put simply, we cannot answer this question directly. 

## Final Question

We can answer related questions, such as: 

\begin{itemize}
    \item $\mathbb{P}(\text{records don't match} \mid \text{we linked them})$; or
    \item $\mathbb{P}(\text{records match} \mid \gamma)$
\end{itemize}

To explore this more in depth, see Binette and Steorts (2020) to see connections to Bayes' rule and see Tepping (1968). 


## Summary

- Soundex algorithm 
- What are the main contributions of Newcombe et al. (1959)?
- Comparison vectors
- What did Fellegi and Sunter (1969) propose (two methods) ?
- How would you summarize the main ideas of this lecture and summarize it to a friend? 

## Supplement

In the supplement, I provide the math that is the basis this problem, which is important to the paper and extensions moving forward. 

Following notation in Kundinger et. al (2024). 

## Notation

Suppose we have two data sets $A$ and $B$ with $n_1$ and $n_2$ records, respectively. 
\vfill
Each records have $F$ fields of information. 
\vfill
We represent the biparite matching by $Z = (Z_1, \ldots, Z_{n_2}),$ where 
\vfill

- $Z_j = i$ for $i \in [n_1]$ if record $j \in B$ matches record $i \in A$ and
- $Z_j = n_1 + j$ if record $j$ in $B$ does not match any record in $A.$

## Comparison Data

Let $$\gamma_{ij} = (\gamma_{ij}^1, \ldots, \gamma_{ij}^F)$$, where 
$\gamma_{ij}^f$ is the comparison of record $i,j$ for field $f.$

Collect all comparison vectors into the matrix 
$$\Gamma = \{ \gamma_{ij} \}_{i=1,j=1}^{n_1,n_2}.$$
